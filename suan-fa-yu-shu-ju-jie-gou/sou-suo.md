# 搜索

**平均查找长度（ASL）：**需和指定key进行比较的关键字的个数的期望值，称为查找算法在查找成功时的平均查找长度。

![](http://images.cnitblog.com/blog/94031/201410/312301180197071.png "search method efficient conclusion")

1. #### 顺序查找

   说明：顺序查找适合于存储结构为顺序存储或链接存储的线性表。

   基本思想：顺序查找也称为线形查找，属于无序查找算法。从数据结构线形表的一端开始，顺序扫描，依次将扫描到的结点关键字与给定值k相比较，若相等则表示查找成功；若扫描结束仍没有找到关键字等于k的结点，表示查找失败。

   复杂度分析：查找成功时的平均查找长度为：（假设每个数据元素的概率相等） ASL = 1/n \* \(1+2+3+…+n\) = \(n+1\)/2 ;

   时间复杂度为O\(n\)。

   ```
   public int SequenceSearch(int[] a, int value) {
       int length = a.length;
       for (int i = 0; i < length; i++) {
           if (a[i] == value) {
               return i;
           }
       }
       return -1;
   }
   ```

2. #### 二分查找

   说明：元素必须是有序的，如果是无序的则要先进行排序操作。

   基本思想：也称为是折半查找，属于有序查找算法。用给定值k先与中间结点的关键字比较，中间结点把线形表分成两个子表，若相等则查找成功；若不相等，再根据k与该中间结点关键字的比较结果确定下一步查找哪个子表，这样递归进行，直到查找到或查找结束发现表中没有这样的结点。

   复杂度分析：最坏情况下，关键词比较次数为log2\(n+1\)，且期望时间复杂度为O\(log2n\)；

   ```
   public int binarySearch(int[] a, int left, int right, int value) {
       if (left > right) {
           return -1;
       }
       int temp = (right + left)/2;
       if (a[temp] == value ) {
           return temp;
       } else if (a[temp] < value) {
           return binarySearch(a, temp + 1, right, value);
       } else {
           return binarySearch(a, left, temp - 1, value);
       }
   }
   ```

3. #### 插值查找

   二分查找中查找点计算如下：mid=\(low+high\)/2, 即mid=low+1/2\*\(high-low\);

   将查找的点改进为如下：mid=low+\(key-a\[low\]\)/\(a\[high\]-a\[low\]\)\*\(high-low\)，

   也就是将上述的比例参数1/2改进为自适应的，根据关键字在整个有序表中所处的位置，让mid值的变化更靠近关键字key，这样也就间接地减少了比较次数。

   基本思想：基于二分查找算法，将查找点的选择改进为自适应选择，可以提高查找效率。当然，差值查找也属于有序查找。

   复杂度分析：查找成功或者失败的时间复杂度均为O\(log2\(log2n\)\)。

   ```
   public int InsertionSearch(int[] a, int left, int right, int value) {
       if (left > right) {
           return -1;
       } 

       int temp = left + (value - a[left]) / (a[right] - a[left]) * (right - left);
       //temp可能超出数组范围
       if (temp > right) {
           temp = right;
       } else if (temp < left) {
           temp = left;
       }

       if (a[temp] == value ) {
           return temp;
       } else if (a[temp] < value) {
           return binarySearch(a, temp + 1, right, value);
       } else {
           return binarySearch(a, left, temp - 1, value);
       }
   }
   ```

4. #### 斐波那契查找
5. #### 树表查找

   1. #### 二叉查找树

      **二叉查找树**（BinarySearch Tree，也叫二叉搜索树，或称二叉排序树）或者是一棵空树，或者是具有下列性质的二叉树：

      1）若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；

      2）若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；

      3）任意节点的左、右子树也分别为二叉查找树。

      二叉查找树性质：对二叉查找树进行中序遍历，即可得到有序的数列。

      复杂度分析：插入和查找的时间复杂度均为O\(logn\)，但是在最坏的情况下仍然会有O\(n\)的时间复杂度。原因在于插入和删除元素的时候，树没有保持平衡（比如，我们查找上图（b）中的“93”，我们需要进行n次查找操作）。我们追求的是在最坏的情况下仍然有较好的时间复杂度，这就是平衡查找树设计的初衷。

   2. #### 2-3树

      **2-3查找树定义**：2-3树运行每个节点保存1个或者两个的值。对于普通的2节点\(2-node\)，他保存1个key和左右两个自己点。对应3节点\(3-node\)，保存两个Key，2-3查找树的定义如下：

      1）要么为空，要么：

      2）对于2节点，该节点保存一个key及对应value，以及两个指向左右节点的节点，左节点也是一个2-3节点，所有的值都比key要小，右节点也是一个2-3节点，所有的值比key要大。

      3）对于3节点，该节点保存两个key及对应value，以及三个指向左中右的节点。左节点也是一个2-3节点，所有的值均比两个key中的最小的key还要小；中间节点也是一个2-3节点，中间节点的key值在两个跟节点key值之间；右节点也是一个2-3节点，节点的所有key值比两个key中的最大的key还要大。

      [![](http://images.cnitblog.com/blog/94031/201403/252248450292152.png "Definition of 2-3 tree")](http://images.cnitblog.com/blog/94031/201403/252248421868855.png)

      2-3查找树的性质：

      1）如果中序遍历2-3查找树，就可以得到排好序的序列；

      2）在一个完全平衡的2-3查找树中，根节点到每一个为空节点的距离都相同。（这也是平衡树中“平衡”一词的概念，根节点到叶节点的最长距离对应于查找算法的最坏情况，而平衡树中根节点到叶节点的距离都一样，最坏情况也具有对数复杂度。）

      **复杂度分析：**

      2-3树的查找效率与树的高度是息息相关的。

      * 在最坏的情况下，也就是所有的节点都是2-node节点，查找效率为lgN
      * 在最好的情况下，所有的节点都是3-node节点，查找效率为log3N约等于0.631lgN

   3. #### 红黑树

      **基本思想：**红黑树的思想就是对2-3查找树进行编码，尤其是对2-3查找树中的3-nodes节点添加额外的信息。红黑树中将节点之间的链接分为两种不同类型，红色链接，他用来链接两个2-nodes节点来表示一个3-nodes节点。黑色链接用来链接普通的2-3节点。特别的，使用红色链接的两个2-nodes来表示一个3-nodes节点，并且向左倾斜，即一个2-node是另一个2-node的左子节点。这种做法的好处是查找的时候不用做任何修改，和普通的二叉查找树相同。

      ![](http://images.cnitblog.com/blog/94031/201403/270024368439888.png "Red black tree")

      **红黑树的定义：**红黑树是一种具有红色和黑色链接的平衡查找树，同时满足：

      * 红色节点向左倾斜
      * 一个节点不可能有两个红色链接
      * 整个树完全黑色平衡，即从根节点到所以叶子结点的路径上，黑色链接的个数都相同。

      下图可以看到红黑树其实是2-3树的另外一种表现形式：如果我们将红色的连线水平绘制，那么他链接的两个2-node节点就是2-3树中的一个3-node节点了。

      [![](http://images.cnitblog.com/blog/94031/201403/270024403113529.png "1-1 correspondence between 2-3 and LLRB")](http://images.cnitblog.com/blog/94031/201403/270024386864059.png)

      红黑树的性质：整个树完全黑色平衡，即从根节点到所以叶子结点的路径上，黑色链接的个数都相同（2-3树的第2）性质，从根节点到叶子节点的距离都相等）。

      复杂度分析：最坏的情况就是，红黑树中除了最左侧路径全部是由3-node节点组成，即红黑相间的路径长度是全黑路径长度的2倍。

      红黑树的平均高度大约为logn。

      下图是一个典型的红黑树，从中可以看到最长的路径\(红黑相间的路径\)是最短路径的2倍：

      [![](http://images.cnitblog.com/blog/94031/201403/270027368747653.png "a typic red black tree")](http://images.cnitblog.com/blog/94031/201403/270027354528654.png)

   4. #### B树

      B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O\(log n\)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。与自平衡二叉查找树不同，B树为系统最优化大块数据的读和写操作。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在数据库和文件系统。

      **B树定义：B树**可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点。

      * 根节点至少有两个子节点

      * 每个节点有M-1个key，并且以升序排列

      * 位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间

      * 其它节点至少有M/2个子节点

      下图是一个M=4 阶的B树:

      ![](http://images.cnitblog.com/blog/94031/201403/290047034539184.png)

      可以看到B树是2-3树的一种扩展，他允许一个节点有多于2个的元素。B树的插入及平衡化操作和2-3树很相似，这里就不介绍了。下面是往B树中依次插入

      **6 10 4 14 5 11 15 3 2 12 1 7 8 8 6 3 6 21 5 15 15 6 32 23 45 65 7 8 6 5 4**

      的演示动画：

      ![](http://files.cnblogs.com/yangecnu/btreebuild.gif)

   5. #### B+树

      **B+树定义：B+**树是对B树的一种变形树，它与B树的差异在于：

      * 有k个子结点的结点必然有k个关键码；
      * 非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。
      * 树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。

      如下图，是一个B+树:

      ![](http://images.cnitblog.com/blog/94031/201403/290050048129679.png "B Plus tree")![](http://files.cnblogs.com/yangecnu/Bplustreebuild.gif)



1. #### 分块查找

   分块查找又称索引顺序查找，它是顺序查找的一种改进方法。

   **算法思想：**

   将n个数据元素"按块有序"划分为m块（m ≤ n）。每一块中的结点不必有序，但块与块之间必须"按块有序"；即第1块中任一元素的关键字都必须小于第2块中任一元素的关键字；而第2块中任一元素又都必须小于第3块中的任一元素，……

   **算法流程：**

   step1 先选取各块中的最大关键字构成一个索引表；

   step2 查找分两个部分：先对索引表进行二分查找或顺序查找，以确定待查记录在哪一块中；然后，在已确定的块中用顺序法进行查找。

2. #### 哈希查找

   **什么是哈希表（Hash）？**

   我们使用一个下标范围比较大的数组来存储元素。可以设计一个函数（哈希函数， 也叫做散列函数），使得每个元素的关键字都与一个函数值（即数组下标）相对应，于是用这个数组单元来存储这个元素；也可以简单的理解为，按照关键字为每一个元素"分类"，然后将这个元素存储在相应"类"所对应的地方。但是，不能够保证每个元素的关键字与函数值是一一对应的，因此极有可能出现对于不同的元素，却计算出了相同的函数值，这样就产生了"冲突"，换句话说，就是把不同的元素分在了相同的"类"之中。后面我们将看到一种解决"冲突"的简便做法。

   **总的来说，"直接定址"与"解决冲突"是哈希表的两大特点。**

   **什么是哈希函数？**

   哈希函数的规则是：通过某种转换关系，使关键字适度的分散到指定大小的的顺序结构中，越分散，则以后查找的时间复杂度越小，空间复杂度越高。

   **算法思想：**哈希的思路很简单，如果所有的键都是整数，那么就可以使用一个简单的无序数组来实现：将键作为索引，值即为其对应的值，这样就可以快速访问任意键的值。这是对于简单的键的情况，我们将其扩展到可以处理更加复杂的类型的键。

   **算法流程：**

   1）用给定的哈希函数构造哈希表；

   2）根据选择的冲突处理方法解决地址冲突；

   常见的解决冲突的方法：拉链法和线性探测法。详细的介绍可以参见：[浅谈算法和数据结构: 十一 哈希表](http://www.cnblogs.com/yangecnu/p/Introduce-Hashtable.html)。

   3）在哈希表的基础上执行哈希查找。

   **哈希表是一个在时间和空间上做出权衡的经典例子。如果没有内存限制，那么可以直接将键作为数组的索引。那么所有的查找时间复杂度为O\(1\)；如果没有时间限制，那么我们可以使用无序数组并进行顺序查找，这样只需要很少的内存。哈希表使用了适度的时间和空间来在这两个极端之间找到了平衡。只需要调整哈希函数算法即可在时间和空间上做出取舍。**

   **复杂度分析**：

   单纯论查找复杂度：对于无冲突的Hash表而言，查找复杂度为O\(1\)（注意，在查找之前我们需要构建相应的Hash表）。

   **使用Hash，我们付出了什么？**  
   　　我们在实际编程中存储一个大规模的数据，最先想到的存储结构可能就是map，也就是我们常说的KV pair，经常使用Python的博友可能更有这种体会。使用map的好处就是，我们在后续处理数据处理时，可以根据数据的key快速的查找到对应的value值。map的本质就是Hash表，那我们在获取了超高查找效率的基础上，我们付出了什么？

   Hash是一种典型**以空间换时间**的算法，比如原来一个长度为100的数组，对其查找，只需要遍历且匹配相应记录即可，从空间复杂度上来看，假如数组存储的是byte类型数据，那么该数组占用100byte空间。现在我们采用Hash算法，我们前面说的Hash必须有一个规则，约束键与存储位置的关系，那么就需要一个固定长度的hash表，此时，仍然是100byte的数组，假设我们需要的100byte用来记录键与位置的关系，那么总的空间为200byte,而且用于记录规则的表大小会根据规则，大小可能是不定的。



